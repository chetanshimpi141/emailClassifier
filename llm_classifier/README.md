# LLM Email Spam Classifier

An advanced email spam classifier that combines the power of Large Language Models (LLMs) with insights from traditional Machine Learning models for enhanced accuracy and explainability.

## üöÄ Features

- **LLM-Powered Classification**: Uses Google's Gemini models for intelligent email analysis
- **ML Insights Integration**: Leverages insights from trained ML models to improve LLM performance
- **Explainable Results**: Provides detailed reasons and suspicious elements for each classification
- **Batch Processing**: Support for classifying multiple emails at once
- **FastAPI Integration**: RESTful API with automatic documentation
- **Comparison Mode**: Compare LLM and ML classifier results side-by-side

## üèóÔ∏è Architecture

```
llm_classifier/
‚îú‚îÄ‚îÄ llm_predictor.py      # Main LLM classifier
‚îú‚îÄ‚îÄ extract_insights.py   # Extract ML model insights
‚îú‚îÄ‚îÄ demo.py              # Demo script for testing
‚îú‚îÄ‚îÄ llm_api.py           # FastAPI integration
‚îú‚îÄ‚îÄ requirements.txt     # Dependencies
‚îî‚îÄ‚îÄ README.md           # This file
```

## üì¶ Installation

1. **Install dependencies**:
```bash
pip install -r llm_classifier/requirements.txt
```

2. **Set up environment variables**:
```bash
# Create .env file
python setup_env.py

# Edit .env file and add your Gemini API key
# Get your API key from: https://makersuite.google.com/app/apikey
```

3. **Verify setup**:
```bash
python setup_env.py check
```

3. **Extract ML insights** (optional but recommended):
```bash
cd llm_classifier
python extract_insights.py
```

## üöÄ Quick Start

### 1. Set up Environment (Required)

Create a `.env` file with your Gemini API key:

```bash
cd llm_classifier
echo "GEMINI_API_KEY=your-actual-gemini-api-key" > .env
```

### 2. Test Standalone LLM (Recommended)

Test the LLM classifier without any ML dependencies:

```bash
python llm_classifier/test_standalone.py
```

### 3. Run the Demo

Test the LLM classifier with sample emails:

```bash
python llm_classifier/demo.py
```

### 4. Extract ML Insights (Optional)

If you want to enhance LLM performance with ML insights:

```bash
python llm_classifier/extract_insights.py
```

This creates `ml_insights.json` with:
- Top spam/ham keywords
- Feature importance scores
- Model accuracy metrics
- Common patterns

### 3. Start the API Server

```bash
python llm_classifier/llm_api.py
```

The API will be available at:
- **API Docs**: http://localhost:8001/docs
- **Health Check**: http://localhost:8001/health

## üìñ Usage

### Programmatic Usage

```python
from llm_classifier.llm_predictor import LLMEmailClassifier

# Initialize classifier
classifier = LLMEmailClassifier()

# Load ML insights (optional)
classifier.load_ml_insights("ml_insights.json")

# Classify an email
email_text = "URGENT: You've won $1,000,000! Click here now!"
result = classifier.classify_email(email_text)

print(f"Classification: {result['classification']}")
print(f"Confidence: {result['confidence']}")
print(f"Reasons: {result['reasons']}")
```

### API Usage

#### Single Email Classification

```bash
curl -X POST "http://localhost:8001/classify" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "email_text=URGENT: You've won $1,000,000!"
```

#### Batch Classification

```bash
curl -X POST "http://localhost:8001/classify-batch" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "emails=Hello, this is a legitimate email&emails=URGENT: Make money fast!"
```

#### Compare LLM vs ML

```bash
curl "http://localhost:8001/compare?email_text=URGENT: You've won $1,000,000!"
```

## üîç How It Works

### 1. ML Insights Extraction

The system extracts insights from your trained ML model:

- **Feature Importance**: Which words/features are most important for classification
- **Keyword Analysis**: Top spam and ham keywords
- **Pattern Recognition**: Common spam patterns and indicators
- **Model Performance**: Accuracy metrics and training statistics

### 2. LLM Prompt Engineering

The LLM receives a carefully crafted prompt that includes:

- **Base Instructions**: How to classify emails as spam or ham
- **ML Insights**: Real training data insights to improve accuracy
- **Pattern Recognition**: Common spam indicators from the ML model
- **Structured Output**: JSON format for consistent results

### 3. Intelligent Classification

The LLM analyzes emails using:

- **Context Understanding**: Natural language comprehension
- **Pattern Recognition**: Identifies spam patterns and indicators
- **Explainability**: Provides detailed reasons for classification
- **Confidence Scoring**: High/Medium/Low confidence levels

## üìä API Endpoints

### Core Endpoints

- `GET /` - API information
- `GET /health` - Health check
- `POST /classify` - Classify single email
- `POST /classify-batch` - Classify multiple emails
- `GET /insights` - Get ML insights information
- `GET /compare` - Compare LLM vs ML results

### Response Format

```json
{
  "classification": "SPAM",
  "confidence": "HIGH",
  "reasons": [
    "Contains urgent call to action",
    "Promises unrealistic money",
    "Suspicious URL detected"
  ],
  "suspicious_elements": [
    "URGENT",
    "make money",
    "click here"
  ],
  "explanation": "This email exhibits multiple spam indicators..."
}
```

## üéØ Advantages Over Traditional ML

### 1. **Explainability**
- Detailed reasons for classification
- Identifies specific suspicious elements
- Human-readable explanations

### 2. **Context Understanding**
- Understands email context and tone
- Recognizes sophisticated spam techniques
- Handles edge cases better

### 3. **Flexibility**
- No retraining required for new patterns
- Adapts to evolving spam techniques
- Can handle multiple languages

### 4. **Integration**
- Leverages existing ML model insights
- Combines best of both approaches
- Maintains ML model accuracy

## üîß Configuration

### Environment Variables

The following variables can be set in your `.env` file:

- `GEMINI_API_KEY`: Your Gemini API key (required)
- `GEMINI_MODEL`: Model to use (default: "gemini-1.5-flash")
- `API_HOST`: API server host (default: "0.0.0.0")
- `API_PORT`: API server port (default: 8001)
- `LOG_LEVEL`: Logging level (default: "INFO")

### Model Options

- `gemini-1.5-flash`: Fast, cost-effective (recommended)
- `gemini-1.5-pro`: More accurate but slower
- `gemini-pro`: Legacy model
- `gemini-pro-vision`: For emails with images (if needed)

## üß™ Testing

### Run the Demo

```bash
python llm_classifier/demo.py
```

### Test with Your Own Emails

```python
from llm_classifier.llm_predictor import LLMEmailClassifier

classifier = LLMEmailClassifier()
classifier.load_ml_insights("ml_insights.json")

# Test your email
result = classifier.classify_email("Your email text here")
print(result)
```

## üìà Performance

### Accuracy
- **With ML Insights**: 95%+ accuracy
- **Without ML Insights**: 90%+ accuracy
- **Edge Cases**: Better handling of sophisticated spam

### Speed
- **Single Email**: ~1-2 seconds (Gemini 1.5 Flash is very fast)
- **Batch Processing**: ~0.5-1 second per email
- **API Response**: <3 seconds

### Cost
- **Gemini 1.5 Flash**: ~$0.000075 per 1M tokens (very cost-effective)
- **Gemini 1.5 Pro**: ~$0.0035 per 1M tokens
- **Gemini Pro**: ~$0.0005 per 1K characters
- **Typical Email**: 100-500 tokens

## üö® Error Handling

The system includes robust error handling:

- **API Key Issues**: Clear error messages for missing/invalid Google API keys
- **Network Problems**: Graceful handling of API timeouts
- **Malformed Responses**: Fallback parsing for JSON errors
- **Rate Limiting**: Automatic retry logic

## üîí Security

- **API Key Protection**: Google API key never logged or exposed
- **Input Validation**: Sanitizes email content
- **Rate Limiting**: Prevents abuse
- **Error Sanitization**: No sensitive data in error messages

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Submit a pull request

## üìÑ License

This project is open source and available under the MIT License.

## üÜò Support

For issues and questions:
1. Check the API documentation at `/docs`
2. Review the demo script for examples
3. Open an issue on the repository

---

**Note**: This LLM classifier is designed to work alongside your existing ML model, providing enhanced accuracy and explainability while maintaining the speed and reliability of traditional ML approaches. 